<!doctype html><html lang=zh-cn><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>Linux下几种常见IO模型 -</title><meta name=Description content="Linux下几种常见IO模型"><meta property="og:title" content="Linux下几种常见IO模型"><meta property="og:description" content="Linux下几种常见IO模型"><meta property="og:type" content="article"><meta property="og:url" content="https://blog.yudlk.com/posts/linux/06-io-model/"><meta property="og:image" content="https://blog.yudlk.com/img/jinx.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2020-10-24T22:00:00+00:00"><meta property="article:modified_time" content="2020-10-24T22:00:00+00:00"><meta property="og:site_name" content="qpt的个人博客"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://blog.yudlk.com/img/jinx.png"><meta name=twitter:title content="Linux下几种常见IO模型"><meta name=twitter:description content="Linux下几种常见IO模型"><meta name=application-name content="面对疾风"><meta name=apple-mobile-web-app-title content="面对疾风"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://blog.yudlk.com/posts/linux/06-io-model/><link rel=prev href=https://blog.yudlk.com/posts/nginx/05-accesslog-analysis/><link rel=next href=https://blog.yudlk.com/posts/go/cond/><link rel=stylesheet href=/css/style.min.cf6878db51c51b2d04ae155284a4403dbee8db33e16c066f954c95279c271fcd.css integrity="sha256-z2h421HFGy0ErhVShKRAPb7o2zPhbAZvlUyVJ5wnH80="><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css as=style onload="this.onload=null,this.rel='stylesheet'"><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload="this.onload=null,this.rel='stylesheet'"><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"Linux下几种常见IO模型","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/blog.yudlk.com\/posts\/linux\/06-io-model\/"},"image":["https:\/\/blog.yudlk.com\/img\/jinx.png"],"genre":"posts","keywords":"Linux","wordcount":4825,"url":"https:\/\/blog.yudlk.com\/posts\/linux\/06-io-model\/","datePublished":"2020-10-24T22:00:00+00:00","dateModified":"2020-10-24T22:00:00+00:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"qpt"},"description":"Linux下几种常见IO模型"}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem('theme')?localStorage.getItem('theme')==='dark':'auto'==='auto'?window.matchMedia('(prefers-color-scheme: dark)').matches:'auto'==='dark')&&document.body.setAttribute('theme','dark')</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title>面对疾风</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/posts/ title=面对疾风>文章 </a><a class=menu-item href=/tags/>标签 </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/about/ title=关于>关于 </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span>
</span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title>面对疾风</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i></a>
<a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i></a>
<span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/posts/ title=面对疾风>文章</a><a class=menu-item href=/tags/ title>标签</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/about/ title=关于>关于</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=toc id=toc-auto><h2 class=toc-title>Contents</h2><div class=toc-content id=toc-content-auto></div></div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Linux下几种常见IO模型</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=https://github.com/barrypt title=Author target=_blank rel="noopener noreffer author" class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>qpt</a></span>&nbsp;<span class=post-category>included in <a href=/categories/linux/><i class="far fa-folder fa-fw" aria-hidden=true></i>Linux</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2020-10-24>2020-10-24</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;4825 words&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;10 minutes&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>Contents</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#1-概述>1. 概述</a></li><li><a href=#2-阻塞式io>2. 阻塞式I/O</a><ul><li><a href=#栗子>栗子</a></li><li><a href=#问题>问题</a></li><li><a href=#解决方案>解决方案</a></li></ul></li><li><a href=#3-非阻塞式io>3. 非阻塞式I/O</a><ul><li><a href=#问题-1>问题</a></li><li><a href=#解决方案-1>解决方案</a></li></ul></li><li><a href=#4-多路复用io>4. 多路复用I/O</a><ul><li><a href=#1-select>1. select</a></li><li><a href=#2-epoll>2. epoll</a></li></ul></li><li><a href=#5-信号驱动式io>5. 信号驱动式I/O</a></li><li><a href=#6-异步io>6. 异步I/O</a></li><li><a href=#7-小结>7. 小结</a></li><li><a href=#8-参考>8. 参考</a></li></ul></nav></div></div><div class=content id=content><p>本文主要简单分析了 Linux 下的几种常见的 I/O 模型。包括 阻塞式I/O（BIO）、非阻塞式I/O（NIO）、I/O多路复用（select、epoll）等。</p><h2 id=1-概述>1. 概述</h2><p>IO 是主存和外部设备 ( 硬盘、终端和网络等 ) 拷贝数据的过程。 IO 是操作系统的底层功能实现，底层通过 I/O 指令进行完成。在本教程中，我们所说的 IO 指的都是<strong>网络 IO</strong>。</p><blockquote><p>技术的出现一定是为了解决当前技术的某些痛点，IO 模型演化也是如此。从最初的 BIO 到 NIO 、select、epoll 都是为了解决某些不得不解决的问题。</p></blockquote><p>五种 I/O 模型</p><ul><li>1）阻塞式I/O：blocking IO</li><li>2）非阻塞式I/O： nonblocking IO</li><li>3）I/O复用（select，poll，epoll&mldr;）：IO multiplexing</li><li>4）信号驱动式I/O（SIGIO）：signal driven IO</li><li>5）异步I/O（POSIX的aio_系列函数）：asynchronous IO</li></ul><p>在这里，我们以一个网络IO来举例，对于一个 network IO (以read举例)，它会涉及到两个系统对象：一个是调用这个 IO 的进程，另一个就是系统内核(kernel)。当一个 read 操作发生时，它会经历两个阶段：</p><ul><li><p><strong>阶段1：<strong>等待数据准备 (Waiting for the data to be ready)，即</strong>将数据从硬件接口到读取到内核态</strong></p><p><strong>阶段2：</strong> 将数据从内核拷贝到进程中 (Copying the data from the kernel to the process)，即<strong>将数据从内核态复制到用户态</strong></p></li></ul><p><img class=lazyload src=/svg/loading.min.svg data-src=https://github.com/barrypt/blog/raw/master/images/linux/io/io-process.png data-srcset="https://github.com/barrypt/blog/raw/master/images/linux/io/io-process.png, https://github.com/barrypt/blog/raw/master/images/linux/io/io-process.png 1.5x, https://github.com/barrypt/blog/raw/master/images/linux/io/io-process.png 2x" data-sizes=auto alt=https://github.com/barrypt/blog/raw/master/images/linux/io/io-process.png title=io-process></p><p>当进程请求 I/O 操作的时候，它执行一个系统调用 syscall 将控制权移交给内核。当内核以这种方式被调用，它随即采取任何必要步骤，找到进程所需数据，并把数据传送到用户空间内的指定缓冲区。</p><p>内核试图对数据进行高速缓存或预读取，因此进程所需数据可能已经在内核空间里了。如果是这样，该数据只需简单地拷贝出来即可。如果数据不在内核空间，则进程被挂起，内核着手把数据读进内存。</p><h2 id=2-阻塞式io>2. 阻塞式I/O</h2><p>在 linux 中，默认情况下所有的 socket 都是 blocking，一个典型的读操作流程大概是这样：</p><ul><li><p><strong>第一步</strong>：通常涉及<code>等待数据从网络中到达</code>。当所有等待数据到达时，它被<code>复制到内核中的某个缓冲区</code>。</p></li><li><p><strong>第二步</strong>：把数据从<code>内核缓冲区</code>复制到<code>应用程序缓冲区</code>。</p></li></ul><p><img class=lazyload src=/svg/loading.min.svg data-src=https://github.com/barrypt/blog/raw/master/images/linux/io/bio.png data-srcset="https://github.com/barrypt/blog/raw/master/images/linux/io/bio.png, https://github.com/barrypt/blog/raw/master/images/linux/io/bio.png 1.5x, https://github.com/barrypt/blog/raw/master/images/linux/io/bio.png 2x" data-sizes=auto alt=https://github.com/barrypt/blog/raw/master/images/linux/io/bio.png title=https://github.com/barrypt/blog/raw/master/images/linux/io/bio.png></p><p>当用户进程调用了 recvfrom 这个系统调用，kernel 就开始了 I/O 的<strong>第一阶段</strong>：准备数据。对于 network io 来说，很多时候数据在一开始还没有到达（比如，还没有收到一个完整的 UDP 包），这个时候 kernel 就要等待足够的数据到来。而在用户进程这边，整 个进程会被阻塞。<strong>第二阶段</strong>当 kernel 等到数据准备好了，它就会将数据从 kernel 中拷贝到用户内存，然后 kernel 返回结果，用户进程才解除 block 的状态，重新运行起来。</p><p><strong>所以，blocking IO 的特点就是在 IO 执行的两个阶段都被 block了。</strong></p><h3 id=栗子>栗子</h3><p>举个栗子，如下所示是一个简单的 socket server：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-go data-lang=go><span class=line><span class=cl><span class=kd>func</span> <span class=nf>main</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>	<span class=c1>// 建立socket，监听端口  第一步:绑定端口
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=nx>netListen</span><span class=p>,</span> <span class=nx>err</span> <span class=o>:=</span> <span class=nx>net</span><span class=p>.</span><span class=nf>Listen</span><span class=p>(</span><span class=s>&#34;tcp&#34;</span><span class=p>,</span> <span class=s>&#34;localhost:9800&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>if</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=nb>panic</span><span class=p>(</span><span class=nx>err</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl>	<span class=c1>// defer 关闭资源，以免引起内存泄漏
</span></span></span><span class=line><span class=cl><span class=c1></span>	<span class=k>defer</span> <span class=nx>netListen</span><span class=p>.</span><span class=nf>Close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>	<span class=nf>Log</span><span class=p>(</span><span class=s>&#34;Waiting for clients&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=k>for</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>		<span class=c1>// 第二步:等待连接
</span></span></span><span class=line><span class=cl><span class=c1></span>		<span class=nx>conn</span><span class=p>,</span> <span class=nx>err</span> <span class=o>:=</span> <span class=nx>netListen</span><span class=p>.</span><span class=nf>Accept</span><span class=p>()</span>
</span></span><span class=line><span class=cl>		<span class=k>if</span> <span class=nx>err</span> <span class=o>!=</span> <span class=kc>nil</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>			<span class=k>continue</span>
</span></span><span class=line><span class=cl>		<span class=p>}</span>
</span></span><span class=line><span class=cl>		<span class=nf>Log</span><span class=p>(</span><span class=nx>conn</span><span class=p>.</span><span class=nf>RemoteAddr</span><span class=p>().</span><span class=nf>String</span><span class=p>(),</span> <span class=s>&#34; tcp connect success&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>		<span class=c1>// 使用goroutine来处理用户的请求
</span></span></span><span class=line><span class=cl><span class=c1></span>		<span class=k>go</span> <span class=nf>handleConnection</span><span class=p>(</span><span class=nx>conn</span><span class=p>)</span>
</span></span><span class=line><span class=cl>	<span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span></code></pre></div><p><strong>说明</strong></p><p>首先 listen 监听端口，然后在一个 for循环中 等待 accept（accept 过程是阻塞的），也就是说每次只能在处理某个请求或者阻塞在 accept。于是每次请求都开一个新的 goroutine 来处理。<code>go handleConnection(conn)</code>。</p><p><strong>具体的调用</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 获取socket fd 文件描述符 假设是 fd5</span>
</span></span><span class=line><span class=cl><span class=nv>socket</span> <span class=o>=</span> fd5
</span></span><span class=line><span class=cl><span class=c1># 绑定端口</span>
</span></span><span class=line><span class=cl><span class=nb>bind</span> <span class=m>9800</span>
</span></span><span class=line><span class=cl><span class=c1># 监听 这个 文件描述符</span>
</span></span><span class=line><span class=cl>listen fd5
</span></span><span class=line><span class=cl><span class=c1># 然后 accept 等待连接过来 比如这里 fd6 就是进来的连接</span>
</span></span><span class=line><span class=cl>accept <span class=nv>fd5</span> <span class=o>=</span> fd6
</span></span><span class=line><span class=cl><span class=c1># 然后从 fd6 读取数据</span>
</span></span><span class=line><span class=cl>recvfrom fd6       
</span></span></code></pre></div><p>可以看到过程中会发生很多 syscall 系统调用。</p><h3 id=问题>问题</h3><p>这样做存在很多问题，需要为每个连接开一个 goroutine ，如果有 1W 链接那就要开 1W goroutine 。</p><ul><li>1）消耗资源，每个 goroutine 是需要一定内存的。</li><li>2）cpu 对这么多 goroutine 调度也会浪费资源</li><li>3）最大问题是 这个 accept 是阻塞的，所以才需要开这么多 goroutine</li></ul><blockquote><p>当然了 goroutine 协程 相对于 线程 是非常轻量级的，调度也是有自己的 GPM 模型，goroutine 的切换也全是在用户态，相较之下已经比线程好很多了。</p></blockquote><p>但是一旦涉及到系统调用 就会很慢，那么能不能让 accept 不阻塞呢？</p><blockquote><p>就是因为 accept 是阻塞的，所以只能开多个 线程 or 协程 来勉强使用。</p></blockquote><h3 id=解决方案>解决方案</h3><p>kernel 中 提供了 sock_nonblock 方法，可以实现非阻塞。</p><h2 id=3-非阻塞式io>3. 非阻塞式I/O</h2><p>linux 下，可以通过设置 socket 使其变为 non-blocking。当对一个 non-blocking socket 执行读操作时，流程是这个样子：</p><p><img class=lazyload src=/svg/loading.min.svg data-src=https://github.com/barrypt/blog/raw/master/images/linux/io/nio.png data-srcset="https://github.com/barrypt/blog/raw/master/images/linux/io/nio.png, https://github.com/barrypt/blog/raw/master/images/linux/io/nio.png 1.5x, https://github.com/barrypt/blog/raw/master/images/linux/io/nio.png 2x" data-sizes=auto alt=https://github.com/barrypt/blog/raw/master/images/linux/io/nio.png title=nio></p><p>从图中可以看出，当用户进程发出 read 操作时，如果 kernel 中的数据还没有准备好，那么它并不会 block 用户进程，而是立刻返回一个 error。</p><p><strong>从用户进程角度讲 ，它发起一个 read 操作后，并不需要等待，而是马上就得到了一个结果</strong>。用户进程判断结果是一个 erro r时，它就知道数据还没有准备好，于是它可以再次 发送 read 操作。</p><p>一旦 kernel 中的数据准备好了，并且又再次收到了用户进程的 system call，那么它马上就将数据拷贝到了用户内存，然后返回。</p><p><strong>所以，用户进程第一个阶段不是阻塞的,需要不断的主动询问kernel数据好了没有；第二个阶段依然总是阻塞的。</strong></p><p>使用 sock_nonblock 使得该过程非阻塞</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 获取socket fd 文件描述符 假设是 fd5</span>
</span></span><span class=line><span class=cl><span class=nv>socket</span> <span class=o>=</span> fd5
</span></span><span class=line><span class=cl><span class=c1># 绑定端口</span>
</span></span><span class=line><span class=cl><span class=nb>bind</span> <span class=m>9800</span>
</span></span><span class=line><span class=cl><span class=c1># 监听 这个 文件描述符</span>
</span></span><span class=line><span class=cl>listen fd5
</span></span><span class=line><span class=cl><span class=c1># 然后 accept 等待连接过来 比如这里 fd6 就是进来的连接</span>
</span></span><span class=line><span class=cl>accept <span class=nv>fd5</span> <span class=o>=</span> fd6
</span></span><span class=line><span class=cl><span class=c1># 然后从 fd6 读取数据</span>
</span></span><span class=line><span class=cl>recvfrom fd6       
</span></span></code></pre></div><h3 id=问题-1>问题</h3><p>虽然是非阻塞了，但是还是存在另外的问题，比如 C10K 问题。</p><p>假设有 1W 客户端，那么每次循环都需要对每个客户端进行一个 系统调用，假设 1W 客户端里其实就只有 1 个是有消息的，相当于另外 9999 次都是浪费。</p><blockquote><p>每次循环时间复杂度为 O(n),但是实际上只需要处理有消息的连接，即O(m)。</p><p>n 为连接数，m 为有消息的连接数</p></blockquote><p>同样的 kernel 通过 提供 select 方法来解决这个问题。</p><h3 id=解决方案-1>解决方案</h3><p>Linux kernel 通过 提供 select 方法来解决这个问题。</p><h2 id=4-多路复用io>4. 多路复用I/O</h2><p>IO 复用同非阻塞 IO 本质一样，不过利用了新的 select 系统调用，由内核来负责本来是请求进程该做的轮询操作。</p><p>看似比非阻塞 IO 还多了一个系统调用开销，不过因为可以支持多路 IO，才算提高了效率。</p><p><strong>多路复用IO复用的是什么？</strong></p><p>我认为复用的是<strong>系统调用</strong>。NIO中是一次系统调用判定一个连接有没有数据，多路复用则通过 select 函数在一次系统调用中传递多个fd，实现一次调用校验多个连接是否有数据。</p><h3 id=1-select>1. select</h3><p>它的基本原理就是 select 这个 function 会不断的轮询所负责的所有 socket，当某个 socket 有数据到达了，就通知用户进程。它的流程如图：</p><p><img class=lazyload src=/svg/loading.min.svg data-src=https://github.com/barrypt/blog/raw/master/images/linux/io/select.png data-srcset="https://github.com/barrypt/blog/raw/master/images/linux/io/select.png, https://github.com/barrypt/blog/raw/master/images/linux/io/select.png 1.5x, https://github.com/barrypt/blog/raw/master/images/linux/io/select.png 2x" data-sizes=auto alt=https://github.com/barrypt/blog/raw/master/images/linux/io/select.png title=select></p><p><strong>select 方法接收多个 文件描述符，最后会返回需要处理的那几个文件描述符</strong>。</p><blockquote><p>这样就不需要遍历所有连接了，只需要处理有消息的那几个。</p></blockquote><p>假设有 1W 连接，即 1W 个文件描述符。</p><p>以前： 循环中 为了处理那几个有消息的连接，调用 1W 次 syscall；</p><p>现在：就先调用 <code>select(fds)</code> ,把 1W 个 文件描述符发给 kernel，内核处理后，假设只有 2个 连接是有消息的，需要处理，就只会返回对应的 fd,比如这里是 fd6、fd7。然后程序拿到需要处理的 fd 列表后再挨个处理，这样就减少了 9998 次 syscall。</p><blockquote><p><strong>注意</strong> 多路复用返回的是状态，具体读写操作还是由程序来控制。</p></blockquote><h4 id=问题-2>问题</h4><p>那么这个模型有没有问题呢？</p><p>问题就是 每次 都要发 1W 个 fd 到 kernel ,然后内核中也要完成 1W 次遍历O(n)，但是以前是 1W 次系统调用，现在是 1次系统调用，里面遍历 1W 次，还是优化了不少的。不过还可以继续优化：</p><ul><li>1） 每次要传 1W 个 fd 给内核</li><li>2） 内核每次要遍历 1W 个 fd,才能返回需要处理的 fds</li></ul><h4 id=解决方案-2>解决方案</h4><p>如何优化呢？</p><p>在内核中开辟一块空间，每次有新的 fd 就直接存到这个空间里，不需要了就移除掉。这样问题1 就解决了。</p><p>问题2 的话就不好处理了，除非内核中提供某种机制，不需要自己去遍历 fds，等有消息来的时候 主动通知内核哪个 fd 来消息了，这样就很完美了。</p><p>于是 kernel 中就提供了 epoll 来解决这些问题。</p><h3 id=2-epoll>2. epoll</h3><p>epoll 与 select 相比就是 不需要自己去遍历 fds 了,由事件驱动的方式，有消息了就主动通知。</p><p>epoll 会为每个 fd 设置一个回调方法，事件触发后会执行回调函数，通过该回调函数会自动把当前fd添加到一个链表中，只需要遍历这个链表就能获取到所有准备好数据的fd。</p><p>一共有 3 个方法</p><ul><li>1）epoll_create()</li><li>2）epoll_ctl()</li><li>3）epoll_wait()</li></ul><p>具体信息都可以通过<code>man name</code>进行查看，比如<code>man epoll_create()</code></p><blockquote><p>如果提示 未找到 man 手册的话 可以手动安装一下 以下是 ubuntu 的安装命令 centos 用 yum install 应该是一样的</p><p>apt-get install manpages-de manpages-de-dev manpages-dev glibc-doc manpages-posix-dev manpages-posix</p></blockquote><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>epoll_create<span class=o>()</span>
</span></span><span class=line><span class=cl>epoll_create<span class=o>()</span> returns a file descriptor referring to the new epoll in‐
</span></span><span class=line><span class=cl>       stance. 
</span></span><span class=line><span class=cl><span class=c1># 返回一个文件描述符。</span>
</span></span><span class=line><span class=cl><span class=c1># 这个就是前面说的，开内核中开辟一块空间来存放 fds 返回的文件描述符就是描述这块空间的</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>epoll_ctl<span class=o>()</span>
</span></span><span class=line><span class=cl><span class=c1># 用于管理 前面创建的空间中的 fds</span>
</span></span><span class=line><span class=cl><span class=c1># 比如新增一个 fd，或者删除某个 fd</span>
</span></span></code></pre></div><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl>epoll_wait<span class=o>()</span>
</span></span><span class=line><span class=cl><span class=c1># 这个就是等 等着某个 fd需要处理了就返回 不用自己去遍历了</span>
</span></span></code></pre></div><p>伪代码</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-shell data-lang=shell><span class=line><span class=cl><span class=c1># 获取socket fd 文件描述符 假设是 fd5</span>
</span></span><span class=line><span class=cl><span class=nv>socket</span> <span class=o>=</span> fd5
</span></span><span class=line><span class=cl><span class=c1># 绑定端口</span>
</span></span><span class=line><span class=cl><span class=nb>bind</span> <span class=m>9800</span>
</span></span><span class=line><span class=cl><span class=c1># 监听 这个 文件描述符</span>
</span></span><span class=line><span class=cl>listen fd5
</span></span><span class=line><span class=cl><span class=c1># 开辟一块用于存储 fds 的空间，假设为 fd8</span>
</span></span><span class=line><span class=cl>epoll_create fd8
</span></span><span class=line><span class=cl><span class=c1># 然后第一件事就是把 前面的 server 端 socket fd5 存进去</span>
</span></span><span class=line><span class=cl>apoll_ctl<span class=o>(</span>fd8,add,fd5,accept<span class=o>)</span>
</span></span><span class=line><span class=cl><span class=c1># 然后就开始等待了</span>
</span></span><span class=line><span class=cl>epoll_wait<span class=o>(</span>fd8<span class=o>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 假设此时有连接进来了 假设为 fd6</span>
</span></span><span class=line><span class=cl>accept fd5---&gt; fd6
</span></span><span class=line><span class=cl><span class=c1># 也是 第一件事就存进去</span>
</span></span><span class=line><span class=cl>apoll_ctl<span class=o>(</span>fd8,fd6<span class=o>)</span>
</span></span><span class=line><span class=cl>...
</span></span><span class=line><span class=cl><span class=c1># 最后 epoll 空间里肯定就存了很多 fd</span>
</span></span></code></pre></div><p>那么问题来了，他是如何指定那个 fd 需要处理的?</p><p>就是靠的<strong>事件驱动</strong>，收到消息后，网卡向 CPU 发送一个 中断事件,CPU 根据这个中断号就能判断出具体是什么事件了，然后通过回调方法就去拿到数据。</p><p>epoll 因为采用 mmap的机制, 使得 内核 socket buffer 和用户空间的 buffer 共享, 从而省去了 socket data copy, 这也意味着, 当 epoll 回调上层的 callback 函数来处理 socket 数据时, 数据已经从内核层 &ldquo;自动&rdquo; 到了用户空间。</p><h4 id=epoll和select区别>epoll和select区别</h4><p>select 需要遍历所有注册的I/O事件，找出准备好的的I/O事件。
而 epoll 则是由内核主动通知哪些I/O事件需要处理，不需要用户线程主动去反复查询，因此大大提高了事件处理的效率。</p><h2 id=5-信号驱动式io>5. 信号驱动式I/O</h2><p><img class=lazyload src=/svg/loading.min.svg data-src=https://github.com/barrypt/blog/raw/master/images/linux/io/signal-driven-io.png data-srcset="https://github.com/barrypt/blog/raw/master/images/linux/io/signal-driven-io.png, https://github.com/barrypt/blog/raw/master/images/linux/io/signal-driven-io.png 1.5x, https://github.com/barrypt/blog/raw/master/images/linux/io/signal-driven-io.png 2x" data-sizes=auto alt=https://github.com/barrypt/blog/raw/master/images/linux/io/signal-driven-io.png title=signal-driven-io></p><h2 id=6-异步io>6. 异步I/O</h2><p><img class=lazyload src=/svg/loading.min.svg data-src=https://github.com/barrypt/blog/raw/master/images/linux/io/async-io.png data-srcset="https://github.com/barrypt/blog/raw/master/images/linux/io/async-io.png, https://github.com/barrypt/blog/raw/master/images/linux/io/async-io.png 1.5x, https://github.com/barrypt/blog/raw/master/images/linux/io/async-io.png 2x" data-sizes=auto alt=https://github.com/barrypt/blog/raw/master/images/linux/io/async-io.png title=async-io></p><p>用户进程发起read操作之后，立刻就可以开始去做其它的事。而另一方面，从kernel的角度，当它受到一个asynchronous read之后，首先它会立刻返回，所以不会对用户进程产生任何block。然后，kernel会等待数据准备完成，然后将数据拷贝到用户内存，当这一切都 完成之后，kernel会给用户进程发送一个signal，告诉它read操作完成了。 在这整个过程中，进程完全没有被block。</p><h2 id=7-小结>7. 小结</h2><p>BIO：内核准备数据时会阻塞，直到数据准备好才返回，然后将数据从内核拷贝到用户程序内存。</p><blockquote><p>因为会阻塞，所以只能用多线程，每个线程处理一个IO，但是多线程消耗大，所以此时不能支持太高并发。</p></blockquote><p>NIO：内核数据没准备好直接返回，由用户程序进行轮训系统调用查看数据是否准备好。</p><blockquote><p>相对BIO优势是非阻塞了，但是有多次系统调用耗费资源。</p></blockquote><p>select：直接将所有fd发送给内核，由内核分别检查数据是否准备好了，减少大量的系统调用。</p><blockquote><p>将多次系统调用降低到了一次，不过还是存在fd复制的消耗</p></blockquote><p>epoll：直接将fd存在内核空间中，省去了select时将fd拷贝到内核空间的消耗。</p><blockquote><p>fd存在内核空间，省去了拷贝的消耗。基本没有太大问题了，如果优化可以考虑降低内核空间的占用。</p></blockquote><ul><li>1）阻塞式I/O：内核准备数据时会阻塞，直到数据准备好才返回，然后将数据从内核拷贝到用户程序内存。<ul><li>因为会阻塞，所以只能用多线程，每个线程处理一个IO，但是多线程消耗大，所以此时不能支持太高并发。</li></ul></li><li>2）非阻塞I/O：内核数据没准备好直接返回，由用户程序进行轮训系统调用查看数据是否准备好。<ul><li>相对BIO优势是非阻塞了，但是有多次系统调用耗费资源。</li></ul></li><li>3）多路复用I/O<ul><li>select：将 fd 发送给内核，由内核遍历检测数据是否准备好，（由应用进行遍历转为内核进行遍历）将多次系统调用转为一次系统调用，不过还是存在fd复制的消耗将。</li><li>epoll：将 fd 存在内存中，省去 fd 传输过程，同时 socket 数据准备好时，由硬件（网卡）发起中断，再次省去系统调用。基本没有太大问题了，如果优化可以考虑降低内核空间的占用。</li></ul></li><li>4）信号驱动式I/O：用得不多</li><li>5）异步I/O：发起调用后直接返回，调用处理完发送信号通知，异步操作，没有任何阻塞。</li></ul><p>其实前四种 I/O 模型都是同步 I/O 操作，他们的区别在于第一阶段，而他们的第二阶段是一样的：在数据从内核复制到应用缓冲区期间（用户空间），进程阻塞于recvfrom 调用。</p><p>可以看到比较优秀的 I/O 模型就是 epoll 了，redis、nginx等等中间件中也是广泛的在使用 epoll。</p><h2 id=8-参考>8. 参考</h2><p><code>《UNIX网络编程：卷一》</code></p><p><code>https://www.zhihu.com/question/19732473/answer/241673170</code></p><p><code>http://blog.chinaunix.net/uid-14874549-id-3487338.html</code></p><p><code>http://www.tianshouzhi.com/api/tutorials/netty/221</code></p></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>Updated on 2020-10-24</span></div></div><div class=post-info-line><div class=post-info-md></div><div class=post-info-share><span><a href=javascript:void(0); title="Share on Twitter" data-sharer=twitter data-url=https://blog.yudlk.com/posts/linux/06-io-model/ data-title=Linux下几种常见IO模型 data-hashtags=Linux><i class="fab fa-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Facebook" data-sharer=facebook data-url=https://blog.yudlk.com/posts/linux/06-io-model/ data-hashtag=Linux><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Hacker News" data-sharer=hackernews data-url=https://blog.yudlk.com/posts/linux/06-io-model/ data-title=Linux下几种常见IO模型><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="Share on Line" data-sharer=line data-url=https://blog.yudlk.com/posts/linux/06-io-model/ data-title=Linux下几种常见IO模型><i data-svg-src=https://cdn.jsdelivr.net/npm/simple-icons@7.3.0/icons/line.svg aria-hidden=true></i></a><a href=javascript:void(0); title="Share on 微博" data-sharer=weibo data-url=https://blog.yudlk.com/posts/linux/06-io-model/ data-title=Linux下几种常见IO模型><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/linux/>Linux</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>Back</a></span>&nbsp;|&nbsp;<span><a href=/>Home</a></span></section></div><div class=post-nav><a href=/posts/nginx/05-accesslog-analysis/ class=prev rel=prev title=Nginx教程(五)---访问日志简单分析><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>Nginx教程(五)---访问日志简单分析</a>
<a href=/posts/go/cond/ class=next rel=next title=Go语言sync.Cond源码分析>Go语言sync.Cond源码分析<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div></article></div></main><footer class=footer><div class=footer-container><div class=footer-line>Powered by <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.100.2">Hugo</a> | Theme - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden=true></i> LoveIt</a></div><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2018 - 2023</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=https://github.com/barrypt target=_blank>qpt</a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:50},comment:{},search:{highlightTag:"em",lunrIndexURL:"/index.json",maxResultLength:10,noResultsFound:"No results found",snippetLength:30,type:"lunr"}}</script><script type=text/javascript src=/js/theme.min.480e58b2c2a8605d406f34667e92ff8f1ae50cfee5b653bead570f004839a983.js integrity="sha256-SA5YssKoYF1AbzRmfpL/jxrlDP7ltlO+rVcPAEg5qYM="></script><script type=text/javascript>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag('js',new Date),gtag('config','G-FL23FNP7CM',{anonymize_ip:!0})</script><script type=text/javascript src="https://www.googletagmanager.com/gtag/js?id=G-FL23FNP7CM" async></script><script>var _hmt=_hmt||[];(function(){var e,t=document.createElement("script");t.src="https://hm.baidu.com/hm.js?4b7c98449a6edf8492a8f3404e6d06a0",e=document.getElementsByTagName("script")[0],e.parentNode.insertBefore(t,e)})()</script><script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-7693630257897132" crossorigin=anonymous></script></body></html>